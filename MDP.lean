import MDP.Counterexample
import MDP.OptimalCost
import MDP.Relations
import MDP.SupSup

/-!
# Markov Decision Processes (MDP)

This module concerns itself with countably infinite branching MDPs.

## Main definitions

* `MDP`: Core definition of MDPs.
* `MDP.FiniteBranching`: A class of MDPs where enabled actions and successors of every state is
  finite.
* `MDP.Path`: Finite paths of MDPs.
* `MDP.Scheduler`: Schedulers resolve nondeterminism. Also known as _Strategy_, _Policy_,
  _Adversary_, etc..
* `MDP.Î¦`: The Bellman operator.
* `MDP.EC`: Expected total cost.
* `MDP.iInf_iSup_EC_comm_lfp_Î¦_all_eq`: Relation of different formalization of _optimal expected
  cost_ equivalent for finitely branching MDPs.
* `MDP.iSup_iSup_EC_eq_lfp_Î¨`: Fixed point characterization of _maximal expected cost_.
-/

namespace MDP

variable {State : Type*} {Act : Type*} {M : MDP State Act}
variable [DecidableEq State]

/-- For finitely branching `MDP`, the optimal expected cost is equivalent under all of the following
  definitions:

* `â¨† n, â¨… ğ’® : ğ”–[M], EC c ğ’® n`: Consider a potentially history dependent scheduler under bounded
  length, and then push the length to the limit.
* `â¨† n, â¨… â„’ : ğ”[M], EC c â„’ n`: Like the previous but limit to history independent (`Markovian`)
  schedulers.
* `â¨… ğ’® : ğ”–[M], â¨† n, EC c ğ’® n`: Push the lengths of paths to the limit, and then consider a
  potentially history dependent scheduler.
* `â¨… â„’ : ğ”[M], â¨† n, EC c â„’ n`: Like the previous but limit to history independent (`Markovian`)
  schedulers.
* `M.lfp_Î¦ c`: The least fixed point of the Bellman operator `M.Î¦`.
-/
theorem iInf_iSup_EC_comm_lfp_Î¦_all_eq [M.FiniteBranching] :
  let S: Set (State â†’ ENNReal) := {
    â¨† n, â¨… ğ’® : ğ”–[M], EC c ğ’® n,
    â¨† n, â¨… â„’ : ğ”[M], EC c â„’ n,
    â¨… ğ’® : ğ”–[M], â¨† n, EC c ğ’® n,
    â¨… â„’ : ğ”[M], â¨† n, EC c â„’ n,
    M.lfp_Î¦ c
  }
  âˆ€ vâ‚ vâ‚‚ : S, vâ‚ = vâ‚‚
:= by
  simp [iSup_iInf_EC_eq_iInf_iSup_EC, iInf_iSup_EC_eq_iInf_iSup_ECâ„’, iSup_iInf_ECâ„’_eq_iInf_iSup_ECâ„’,
    â† iSup_iInf_EC_eq_lfp_Î¦]

end MDP
